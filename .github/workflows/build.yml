name: Fabric Validation

on:
  pull_request:
    branches: [ main, dev ]
  workflow_dispatch:

permissions:
  contents: read
  pull-requests: write
  checks: write

jobs:
  FabricValidation:
    runs-on: windows-latest
    outputs:
      semantic_outcome: ${{ steps.semanticmodel.outcome }}
      report_outcome: ${{ steps.report.outcome }}
      naming_outcome: ${{ steps.naming.outcome }}
      unused_outcome: ${{ steps.unused.outcome }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup folders
        run: |
          New-Item -ItemType Directory -Force -Path ./scripts/testResults
          
      - name: Run Semantic Model validation
        id: semanticmodel
        run: ./scripts/bpa-semanticmodel.ps1 -path "." -src "./src/*.SemanticModel"
        continue-on-error: true

      - name: Run Report validation
        id: report
        run: ./scripts/bpa-report.ps1 -path "." -src "./src/*.Report"
        continue-on-error: true

      - name: Check naming conventions
        id: naming
        run: ./scripts/naming_conv_test.ps1
        continue-on-error: true

      - name: Check unused fields
        id: unused
        run: ./scripts/unused-fields.ps1 -path "." -srcFolder "./src"
        continue-on-error: true
      
      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-results
          path: "**/testResults/*.xml"
          retention-days: 7

  PublishAndComment:
    runs-on: ubuntu-latest
    needs: FabricValidation
    if: always()
    permissions:
      pull-requests: write
      checks: write
      contents: read
    steps:
      - name: Checkout repository 
        uses: actions/checkout@v4

      - name: Download test results
        uses: actions/download-artifact@v4
        with:
          name: test-results
          path: downloaded-test-results

      - name: Publish test results
        uses: EnricoMi/publish-unit-test-result-action@v2
        with:
          files: "downloaded-test-results/**/*.xml"

      - name: Comment PR and Check Failures
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const path = require('path');

            function getTestCounts(xmlRelativePath) {
              const basePath = 'downloaded-test-results/scripts/testResults'; 
              const fullPath = path.join(basePath, xmlRelativePath);
              let passed = 0;
              let failed = 0;

              try {
                if (!fs.existsSync(fullPath)) {
                  core.warning(`Test result file not found: ${fullPath}`);
                  return { passed, failed };
                }
                const xmlContent = fs.readFileSync(fullPath, 'utf8');
                
                let match = xmlContent.match(/<test-run[^>]*\sfailed="(\d+)"[^>]*\spassed="(\d+)"/);
                if (!match) { 
                    match = xmlContent.match(/<test-run[^>]*\spassed="(\d+)"[^>]*\sfailed="(\d+)"/);
                }

                if (match && match.length === 3) {
                  failed = parseInt(match[1]); 
                  passed = parseInt(match[2]); 
                  if (isNaN(failed) || isNaN(passed)) { 
                    passed = parseInt(match[1]);
                    failed = parseInt(match[2]);
                  }
                } else {
                  match = xmlContent.match(/<test-suite[^>]*\sfailed="(\d+)"[^>]*\spassed="(\d+)"/);
                  if (!match) {
                      match = xmlContent.match(/<test-suite[^>]*\spassed="(\d+)"[^>]*\sfailed="(\d+)"/);
                  }
                  if (match && match.length === 3) {
                    failed = parseInt(match[1]);
                    passed = parseInt(match[2]);
                    if (isNaN(failed) || isNaN(passed)) {
                        passed = parseInt(match[1]);
                        failed = parseInt(match[2]);
                    }
                  } else {
                    core.warning(`Could not parse passed/failed counts from ${fullPath} using regex on test-run or test-suite.`);
                    passed = (xmlContent.match(/<test-case[^>]*result="Passed"/g) || []).length + (xmlContent.match(/<test-case[^>]*result="Succeeded"/g) || []).length;
                    failed = (xmlContent.match(/<test-case[^>]*result="Failed"/g) || []).length;
                  }
                }
              } catch (e) {
                core.error(`Error processing ${fullPath}: ${e.message}`);
              }
              return { passed, failed };
            }

            const semanticFile = 'SemanticModel_PesterResults.xml'; 
            const reportFile = 'Report_PesterResults.xml';         
            const namingFile = 'Naming_PesterResults.xml';         
            const unusedFile = 'Unused_PesterResults.xml';         

            const semanticCounts = getTestCounts(semanticFile);
            const reportCounts = getTestCounts(reportFile);
            const namingCounts = getTestCounts(namingFile);
            const unusedCounts = getTestCounts(unusedFile);

            const semanticOverallStatus = "${{ needs.FabricValidation.outputs.semantic_outcome }}" == "success" ? "✅" : "❌";
            const reportOverallStatus = "${{ needs.FabricValidation.outputs.report_outcome }}" == "success" ? "✅" : "❌";
            const namingOverallStatus = "${{ needs.FabricValidation.outputs.naming_outcome }}" == "success" ? "✅" : "❌";
            const unusedOverallStatus = "${{ needs.FabricValidation.outputs.unused_outcome }}" == "success" ? "✅" : "❌";
            
            const body = `## Resultados de validación
            
            | Validación              | Estado | Detalle (Fallados / Pasados) |
            |-------------------------|--------|------------------------------|
            | Modelos semánticos      | ${semanticOverallStatus}       | ❌ ${semanticCounts.failed} / ✅ ${semanticCounts.passed}   |
            | Reportes                | ${reportOverallStatus}       | ❌ ${reportCounts.failed} / ✅ ${reportCounts.passed}   |
            | Convenciones de nombres | ${namingOverallStatus}       | ❌ ${namingCounts.failed} / ✅ ${namingCounts.passed}   |
            | Campos no utilizados    | ${unusedOverallStatus}       | ❌ ${unusedCounts.failed} / ✅ ${unusedCounts.passed}   |
            
            [Ver detalles completos de la ejecución](${context.payload.repository.html_url}/actions/runs/${{ github.run_id }})
            `;
            
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });
            
            const botComment = comments.find(comment => {
              return comment.user && comment.user.login === 'github-actions[bot]' && comment.body.includes('Resultados de validación');
            });
            
            if (botComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: body
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: body
              });
            }
            
            const allPassedByOutcome = 
              "${{ needs.FabricValidation.outputs.semantic_outcome }}" == "success" && 
              "${{ needs.FabricValidation.outputs.report_outcome }}" == "success" && 
              "${{ needs.FabricValidation.outputs.naming_outcome }}" == "success" && 
              "${{ needs.FabricValidation.outputs.unused_outcome }}" == "success";
              
            if (!allPassedByOutcome && "${{ github.base_ref }}" == "main") {
              core.setFailed("Al menos una validación (basada en el outcome del paso) falló. No se pueden fusionar PRs con errores a la rama main.");
            }
